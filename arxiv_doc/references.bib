@article{dahlmann2021ebert,
  title={Deploying a BERT-based Query-Title Relevance Classifier in a Production System: a View from the Trenches},
  author={Dahlmann, Leonard and Lancewicki, Tomer},
  journal={arXiv preprint arXiv:2108.10197},
  year={2021}
}


# Inigo and Ari
@Conference{c-Urteaga2018a,
  author    = {I{\~n}igo Urteaga and Chris H. Wiggins},
  title     = {{Sequential Monte Carlo for Dynamic Softmax Bandits}},
  booktitle = {1st Symposium on Advances in Approximate Bayesian Inference (AABI 2018)},
  year      = {2018},
}

@Conference{c-Urteaga2018b,
  author    = {I{\~n}igo Urteaga and Chris H. Wiggins},
  title     = {{Nonparametric Gaussian mixture models for the multi-armed contextual bandit}},
  booktitle = {NeurIPS 2018 Workshop ``All of Bayesian Nonparametrics (Especially the Useful Bits)''},
  year      = {2018},
}

@Conference{c-Urteaga2018c,
  author    = {I{\~n}igo Urteaga and Chris H. Wiggins},
  title     = {{Bandits with sequentially observed rewards: a Bayesian generative Thompson sampling approach}},
  booktitle = {NeurIPS 2018 Workshop ``Reinforcement Learning under Partial Observability''},
  year      = {2018},
}

@inproceedings{urteaga2018variational,
  title={Variational inference for the multi-armed contextual bandit},
  author={I{\~n}igo Urteaga and Chris Wiggins},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={698--706},
  year={2018}
}

@Article{j-Urteaga2018,
  author       = {{\~n}igo Urteaga and Chris H Wiggins},
  journal      = {arXiv preprint arXiv:1808.02932},
  title        = {{Nonparametric Gaussian Mixture Models for the Multi-Armed Bandit}},
  year         = {2018},
  primaryclass = {stat.ML},
}

@inproceedings{fox2016taming,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox*, Roy and Pakman*, Ari and Tishby, Naftali},
  booktitle={Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
  pages={202--211},
  year={2016}
}

@inproceedings{shababo2013bayesian,
  title={Bayesian inference and online experimental design for mapping neural microcircuits},
  author={Shababo, Ben and Paige, Brooks and Pakman, Ari and Paninski, Liam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1304--1312},
  year={2013}
}

@inproceedings{pakman2013auxiliary,
  title={{Auxiliary-variable exact Hamiltonian Monte Carlo samplers for binary distributions}},
  author={Pakman, Ari and Paninski, Liam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2490--2498},
  year={2013}
}

@inproceedings{carlson2016partition,
  title={{Partition functions from Rao-Blackwellized tempered sampling}},
  author={Carlson*, David and Stinson*, Patrick and Pakman*, Ari and Paninski, Liam},
  booktitle={International Conference on Machine Learning},
  pages={2896--2905},
  year={2016}
}

@inproceedings{pakman2017stochastic,
  title={Stochastic bouncy particle sampler},
  author={Pakman*, Ari and Gilboa*, Dar and Carlson, David and Paninski, Liam},
  booktitle={International Conference on Machine Learning},
  pages={2741--2750},
  year={2017}
}

@inproceedings{pakman2020,
 title = {{Neural Clustering Processes}},
 year = {2020},
 author = {Pakman, Ari and Wang, Yueqi and Mitelut, Catalin and Lee, JinHyung and Liam Paninski},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

#MAB online
@InProceedings{ip-Agarwal2013,
  author    = {Deepak Agarwal},
  title     = {{Computational Advertising: The Linkedin Way}},
  booktitle = {Proceedings of the 22Nd ACM International Conference on Information \& Knowledge Management},
  year      = {2013},
  series    = {CIKM '13},
  pages     = {1585--1586},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2514690},
  doi       = {10.1145/2505515.2514690},
  isbn      = {978-1-4503-2263-8},
  keywords  = {computational advertising, machine learning, social networks},
  location  = {San Francisco, California, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2505515.2514690},
}

@Article{j-Li2010,
  Title                    = {{A Contextual-Bandit Approach to Personalized News Article Recommendation}},
  Author                   = {Lihong Li and Wei Chu and John Langford and Robert E. Schapire},
  Journal                  = {CoRR},
  Year                     = {2010},
  Volume                   = {abs/1003.0146},

  Owner                    = {iurteaga},
  Timestamp                = {2017.04.04}
}

@InProceedings{ip-Chu2009,
  Title                    = {{A Case Study of Behavior-driven Conjoint Analysis on Yahoo!: Front Page Today Module}},
  Author                   = {Chu, Wei and Park, Seung-Taek and Beaupre, Todd and Motgi, Nitin and Phadke, Amit and Chakraborty, Seinjuti and Zachariah, Joe},
  Booktitle                = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Year                     = {2009},

  Address                  = {New York, NY, USA},
  Pages                    = {1097--1104},
  Publisher                = {ACM},
  Series                   = {KDD '09},

  Acmid                    = {1557138},
  Doi                      = {10.1145/1557019.1557138},
  ISBN                     = {978-1-60558-495-9},
  Keywords                 = {classification, clustering, conjoint analysis, logistic regression, segmentation, tensor product},
  Location                 = {Paris, France},
  Numpages                 = {8},
  Owner                    = {iurteaga},
  Timestamp                = {2018.05.15}
}

@InProceedings{ip-Chu2011,
  Title                    = {{Contextual Bandits with Linear Payoff Functions}},
  Author                   = {Wei Chu and Lihong Li and Lev Reyzin and Robert Schapire},
  Booktitle                = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  Year                     = {2011},

  Address                  = {Fort Lauderdale, FL, USA},
  Editor                   = {Geoffrey Gordon and David Dunson and Miroslav Dud\'ik},
  Month                    = {11--13 Apr},
  Pages                    = {208--214},
  Publisher                = {PMLR},
  Series                   = {Proceedings of Machine Learning Research},
  Volume                   = {15},

  Abstract                 = {In this paper we study the contextual bandit problem (also known as the multi-armed bandit problem with expert advice) for linear payoff functions. For T rounds, K actions, and d dimensional feature vectors, we prove an $O(\sqrt{Td\ln^3(KT\ln(T)/\delta}))$ regret bound that holds with probability $1-\delta$ for the simplest known (both conceptually and computationally) efficient upper confidence bound algorithm for this problem. We also prove a lower bound of \Omega(\sqrt{Td})$ for this setting, matching the upper bound up to logarithmic factors.},
  Url                      = {http://proceedings.mlr.press/v15/chu11a.html}
}

@Misc{Netflix2017,
  author       = {Netflix},
  title        = {{Artwork Personalization at Netflix}},
  howpublished = {{\href{https://medium.com/netflix-techblog/artwork-personalization-c589f074ad76}{medium.com}}},
  month        = {December},
  year         = {2017},
}

@InProceedings{ip-Hill2017,
  author       = {Daniel N Hill and Houssam Nassif and Yi Liu and Anand Iyer and SVN Vishwanathan},
  title        = {{An efficient bandit algorithm for realtime multivariate optimization}},
  booktitle    = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year         = {2017},
  pages        = {1813--1821},
  organization = {ACM},
}


# RL
@Book{b-Sutton1998,
  Title                    = {{Reinforcement Learning: An Introduction}},
  Author                   = {Richard S. Sutton and Andrew G. Barto},
  Publisher                = {MIT Press: Cambridge, MA},
  Year                     = {1998},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10}
}

@Article{j-Gosavi2009,
  Title                    = {{Reinforcement learning: A tutorial survey and recent advances}},
  Author                   = {Abhijit Gosavi},
  Journal                  = {INFORMS Journal on Computing},
  Year                     = {2009},
  Number                   = {2},
  Pages                    = {178--192},
  Volume                   = {21},

  Publisher                = {INFORMS}
}

@Article{j-Mnih2015,
  author    = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A. Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin Riedmiller and Andreas K. Fidjeland and Georg Ostrovski and Stig Petersen and Charles Beattie and Amir Sadik and Ioannis Antonoglou and Helen King and Dharshan Kumaran and Daan Wierstra and Shane Legg and Demis Hassabis},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  year      = {2015},
  volume    = {518},
  number    = {7540},
  pages     = {529},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/nature14236},
}

@Article{j-Silver2017,
  author    = {David Silver and Julian Schrittwieser and Karen Simonyan and Ioannis Antonoglou and Aja Huang and Arthur Guez and Thomas Hubert and Lucas Baker and Matthew Lai and Adrian Bolton and Yutian Chen and Timothy Lillicrap and Fan Hui and Laurent Sifre and George van den Driessche and Thore Graepel and Demis Hassabis},
  title     = {Mastering the game of go without human knowledge},
  journal   = {Nature},
  year      = {2017},
  volume    = {550},
  number    = {7676},
  pages     = {354},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/nature24270},
}

# MABs
@Article{j-Lai1985,
  Title                    = {{Asymptotically Efficient Adaptive Allocation Rules}},
  Author                   = {Tze Leung Lai and Herbert Robbins},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1985},

  Month                    = {mar},
  Number                   = {1},
  Pages                    = {4--22},
  Volume                   = {6},

  Acmid                    = {2609757},
  Address                  = {Orlando, FL, USA},
  Doi                      = {10.1016/0196-8858(85)90002-8},
  ISSN                     = {0196-8858},
  Issue_date               = {March, 1985},
  Numpages                 = {19},
  Owner                    = {iurteaga},
  Publisher                = {Academic Press, Inc.},
  Timestamp                = {2017.05.10}
}


@Article{j-Lai1987,
  Title                    = {{Adaptive Treatment Allocation and the Multi-Armed Bandit Problem}},
  Author                   = {Tze Leung Lai},
  Journal                  = {The Annals of Statistics},
  Year                     = {1987},
  Number                   = {3},
  Pages                    = {1091-1114},
  Volume                   = {15},

  ISSN                     = {00905364},
  Owner                    = {iurteaga},
  Publisher                = {Institute of Mathematical Statistics},
  Timestamp                = {2017.05.10}
}

@Book{b-Lattimore2020,
  author    = {Tor Lattimore and Csaba Szepesv{\'a}ri},
  publisher = {Cambridge University Press},
  title     = {Bandit algorithms},
  year      = {2020},
}

@InProceedings{ip-Garivier2011a,
  author    = {Aur\'{e}lien Garivier and Olivier Capp\'{e}},
  title     = {{The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond}},
  booktitle = {Proceedings of the 24th Annual Conference on Learning Theory},
  year      = {2011},
  editor    = {Sham M. Kakade and Ulrike von Luxburg},
  volume    = {19},
  series    = {Proceedings of Machine Learning Research},
  pages     = {359--376},
  address   = {Budapest, Hungary},
  month     = {09--11 Jun},
  publisher = {PMLR},
  abstract  = {This paper presents a finite-time analysis of the KL-UCB algorithm, an online, horizon-free  index policy for stochastic bandit problems.  We prove two distinct results: first, for arbitrary bounded rewards, the KL-UCB algorithm  satisfies a uniformly better regret bound than UCB and its variants; second, in the special case of  Bernoulli rewards, it reaches the lower bound of Lai and Robbins.  Furthermore, we show that simple adaptations of the KL-UCB algorithm are also optimal for  specific classes of (possibly unbounded) rewards, including those generated from exponential  families of distributions.  A large-scale numerical study comparing KL-UCB with its main competitors (UCB, MOSS,  UCB-Tuned, UCB-V, DMED) shows that KL-UCB is remarkably efficient and stable, including for short time horizons. KL-UCB is also the only method that always performs better  than the basic UCB policy.  Our regret bounds rely on deviations results of independent interest which are stated and proved  in the Appendix. As a by-product, we also obtain an improved regret bound for the standard UCB  algorithm.},
  file      = {garivier11a.pdf:http\://proceedings.mlr.press/v19/garivier11a/garivier11a.pdf:PDF},
  url       = {http://proceedings.mlr.press/v19/garivier11a.html},
}


@Article{j-Agrawal2011,
  Title                    = {{Analysis of Thompson Sampling for the multi-armed bandit problem}},
  Author                   = {Shipra Agrawal and Navin Goyal},
  Journal                  = {CoRR},
  Year                     = {2011},
  Volume                   = {abs/1111.1797},

  Abstract                 = {The multi-armed bandit problem is a popular model for studying exploration/exploitation trade-off in sequential decision problems. Many algorithms are now available for this well-studied problem. One of the earliest algorithms, given by W. R. Thompson, dates back to 1933. This algorithm, referred to as Thompson Sampling, is a natural Bayesian algorithm. The basic idea is to choose an arm to play according to its probability of being the best arm. Thompson Sampling algorithm has experimentally been shown to be close to optimal. In addition, it is efficient to implement and exhibits several desirable properties such as small regret for delayed feedback. However, theoretical understanding of this algorithm was quite limited. In this paper, for the first time, we show that Thompson Sampling algorithm achieves logarithmic expected regret for the multi-armed bandit problem. More precisely, for the two-armed bandit problem, the expected regret in time T is O(lnTÎ+1Î3). And, for the N-armed bandit problem, the expected regret in time T is O([(âNi=21Î2i)2]lnT). Our bounds are optimal but for the dependence on Îi and the constant factors in big-Oh.},
  Keywords                 = {Thompson sampling, multi-armed bandit, bounds},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.20}
}


@InCollection{ic-Abbasi-yadkori2011,
  author    = {Yasin Abbasi-yadkori and P\'{a}l, D\'{a}vid and Csaba Szepesv\'{a}ri},
  title     = {{Improved Algorithms for Linear Stochastic Bandits}},
  booktitle = {Advances in Neural Information Processing Systems 24},
  publisher = {Curran Associates, Inc.},
  year      = {2011},
  editor    = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
  pages     = {2312--2320},
  url       = {http://papers.nips.cc/paper/4417-improved-algorithms-for-linear-stochastic-bandits.pdf},
}

@Article{j-Agrawal2012,
  Title                    = {{Thompson Sampling for Contextual Bandits with Linear Payoffs}},
  Author                   = {Shipra Agrawal and Navin Goyal},
  Journal                  = {CoRR},
  Year                     = {2012},
  Volume                   = {abs/1209.3352},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10}
}


@InCollection{ic-Korda2013,
  Title                    = {{Thompson Sampling for 1-Dimensional Exponential Family Bandits}},
  Author                   = {Nathaniel Korda and Emilie Kaufmann and R{\'e}mi Munos},
  Booktitle                = {Advances in Neural Information Processing Systems 26},
  Publisher                = {Curran Associates, Inc.},
  Year                     = {2013},
  Editor                   = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
  Pages                    = {1448--1456},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.19}
}

@inproceedings{ip-Shuai2016,
author = {Li, Shuai and Karatzoglou, Alexandros and Gentile, Claudio},
title = {Collaborative Filtering Bandits},
year = {2016},
isbn = {9781450340694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2911451.2911548},
doi = {10.1145/2911451.2911548},
booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {539–548},
numpages = {10},
keywords = {collaborative filtering, regret, filtering and recommending, clustering, recommender systems, computational advertising, online learning, bandits},
location = {Pisa, Italy},
series = {SIGIR ’16}
}

  
@inproceedings{ip-gentile2014,
  title={Online clustering of bandits},
  author={Gentile, Claudio and Li, Shuai and Zappella, Giovanni},
  booktitle={International Conference on Machine Learning},
  pages={757--765},
  year={2014}
}

@Article{bert,
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title   = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
  journal = {arXiv preprint arXiv:1810.04805},
  year    = {2018},
  url     = {https://arxiv.org/abs/1810.04805},
}

@Article{roberta,
  author  = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  title   = {Roberta: A robustly optimized bert pretraining approach},
  journal = {arXiv preprint arXiv:1907.11692},
  year    = {2019},
  url     = {https://arxiv.org/abs/1907.11692},
}

@article{schubert,
  title={schuBERT: Optimizing Elements of BERT},
  author={Khetan, Ashish and Karnin, Zohar},
  journal={arXiv preprint arXiv:2005.06628},
  year={2020}
}

@article{distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{autosem,
  title={Autosem: Automatic task selection and mixing in multi-task learning},
  author={Guo, Han and Pasunuru, Ramakanth and Bansal, Mohit},
  journal={arXiv preprint arXiv:1904.04153},
  year={2019}
}

@article{nlpMultiTask,
  title={Task Selection Policies for Multitask Learning},
  author={Glover, John and Hokamp, Chris},
  journal={arXiv preprint arXiv:1907.06214},
  year={2019}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@Article{j-Masrani2019,
  author  = {Masrani, Vaden and Le, Tuan Anh and Wood, Frank},
  title   = {The thermodynamic variational objective},
  journal = {arXiv preprint arXiv:1907.00031},
  year    = {2019},
}

@InProceedings{ip-Krause2011,
  author    = {Andreas Krause and Cheng Ong},
  title     = {{Contextual Gaussian Process Bandit Optimization}},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2011},
  editor    = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K. Q. Weinberger},
  volume    = {24},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper/2011/file/f3f1b7fc5a8779a9e618e1f23a7b7860-Paper.pdf},
}

@InProceedings{ip-Bogunovic2016,
  author       = {Bogunovic, Ilija and Scarlett, Jonathan and Cevher, Volkan},
  title        = {Time-varying Gaussian process bandit optimization},
  booktitle    = {Artificial Intelligence and Statistics},
  year         = {2016},
  pages        = {314--323},
  organization = {PMLR},
}

@Article{j-Hennig2012,
  author  = {Philipp Hennig and Christian J. Schuler},
  title   = {{Entropy Search for Information-Efficient Global Optimization}},
  journal = {Journal of Machine Learning Research},
  year    = {2012},
  volume  = {13},
  number  = {57},
  pages   = {1809-1837},
  url     = {http://jmlr.org/papers/v13/hennig12a.html},
}

@InProceedings{ip-Klein2017,
  author    = {Aaron Klein and Stefan Falkner and Simon Bartels and Philipp Hennig and Frank Hutter},
  title     = {{Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets}},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  year      = {2017},
  editor    = {Aarti Singh and Jerry Zhu},
  volume    = {54},
  series    = {Proceedings of Machine Learning Research},
  pages     = {528--536},
  address   = {Fort Lauderdale, FL, USA},
  month     = {20--22 Apr},
  publisher = {PMLR},
  abstract  = {Bayesian optimization has become a successful tool for hyperparameter optimization of machine learning algorithms, such as support vector machines or deep neural networks. Despite its success, for large datasets, training and validating a single configuration often takes hours, days, or even weeks, which limits the achievable performance. To accelerate hyperparameter optimization, we propose a generative model for the validation error as a function of training set size, which is learned during the optimization process and allows exploration of preliminary configurations on small subsets, by extrapolating to the full dataset. We construct a Bayesian optimization procedure, dubbed FABOLAS, which models loss and training time as a function of dataset size and automatically trades off high information gain about the global optimum against computational cost. Experiments optimizing support vector machines and deep neural networks show that FABOLAS often finds high-quality solutions 10 to 100 times faster than other state-of-the-art Bayesian optimization methods or the recently proposed bandit strategy Hyperband.},
  file      = {klein17a.pdf:http\://proceedings.mlr.press/v54/klein17a/klein17a.pdf:PDF},
  url       = {http://proceedings.mlr.press/v54/klein17a.html},
}

@InProceedings{ip-Hernandez-Lobato2014,
  author    = {Jos\'{e} Miguel Hern\'{a}ndez-Lobato and Matthew W Hoffman and Zoubin Ghahramani},
  title     = {{Predictive Entropy Search for Efficient Global Optimization of Black-box Functions}},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2014},
  editor    = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
  volume    = {27},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper/2014/file/069d3bb002acd8d7dd095917f9efe4cb-Paper.pdf},
}

@Article{j-Turc2019,
  author  = {Iulia Turc and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  title   = {{Well-read students learn better: On the importance of pre-training compact models}},
  journal = {arXiv preprint arXiv:1908.08962},
  year    = {2019},
}

@Article{j-Yang2019,
  author  = {Zhilin Yang and Zihang Dai and Yiming Yang and Jaime Carbonell and Ruslan Salakhutdinov and Quoc V Le},
  title   = {{Xlnet: Generalized autoregressive pretraining for language understanding}},
  journal = {arXiv preprint arXiv:1906.08237},
  year    = {2019},
}

@Article{j-Lewis2019,
  author  = {Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
  title   = {{Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension}},
  journal = {arXiv preprint arXiv:1910.13461},
  year    = {2019},
  url     = {https://arxiv.org/abs/1910.13461},
}

@Article{j-Conneau2019,
  author  = {Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  title   = {{Unsupervised cross-lingual representation learning at scale}},
  journal = {arXiv preprint arXiv:1911.02116},
  year    = {2019},
  url     = {https://arxiv.org/abs/1911.02116},
}

@Article{j-Bouneffouf2019,
  author  = {Djallel Bouneffouf and Irina Rish},
  journal = {arXiv preprint arXiv:1904.10040},
  title   = {{A survey on practical applications of multi-armed and contextual bandits}},
  year    = {2019},
}

@Article{j-Ghavamzadeh2016,
  author        = {Mohammad Ghavamzadeh and Shie Mannor and Joelle Pineau and Aviv Tamar},
  journal       = {Foundations and Trends in Machine Learning, Vol. 8: No. 5-6, pp 359-492, 2015},
  title         = {{Bayesian Reinforcement Learning: A Survey}},
  year          = {2016},
  month         = sep,
  abstract      = {Bayesian methods for machine learning have been widely investigated, yielding principled methods for incorporating prior information into inference algorithms. In this survey, we provide an in-depth review of the role of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian reasoning in RL are: 1) it provides an elegant approach to action-selection (exploration/exploitation) as a function of the uncertainty in learning; and 2) it provides a machinery to incorporate prior knowledge into the algorithms. We first discuss models and methods for Bayesian inference in the simple single-step Bandit model. We then review the extensive recent literature on Bayesian methods for model-based RL, where prior information can be expressed on the parameters of the Markov model. We also present Bayesian methods for model-free RL, where priors are expressed over the value function or policy class. The objective of the paper is to provide a comprehensive survey on Bayesian RL algorithms and their theoretical and empirical properties.},
  archiveprefix = {arXiv},
  doi           = {10.1561/2200000049},
  eprint        = {1609.04436},
  file          = {:j-Ghavamzadeh2016 - Bayesian Reinforcement Learning_ a Survey.pdf:PDF;:Ghavamzadeh2016 - Bayesian Reinforcement Learning_ a Survey.pdf:PDF},
  keywords      = {cs.AI, cs.LG, stat.ML},
  primaryclass  = {cs.AI},
}

@Article{j-Gururangan2020,
  author        = {Suchin Gururangan and Ana Marasović and Swabha Swayamdipta and Kyle Lo and Iz Beltagy and Doug Downey and Noah A. Smith},
  journal       = {arXiv preprint},
  title         = {{Don't Stop Pretraining: Adapt Language Models to Domains and Tasks}},
  year          = {2020},
  month         = apr,
  abstract      = {Language models pretrained on text from a wide variety of sources form the foundation of today's NLP. In light of the success of these broad-coverage models, we investigate whether it is still helpful to tailor a pretrained model to the domain of a target task. We present a study across four domains (biomedical and computer science publications, news, and reviews) and eight classification tasks, showing that a second phase of pretraining in-domain (domain-adaptive pretraining) leads to performance gains, under both high- and low-resource settings. Moreover, adapting to the task's unlabeled data (task-adaptive pretraining) improves performance even after domain-adaptive pretraining. Finally, we show that adapting to a task corpus augmented using simple data selection strategies is an effective alternative, especially when resources for domain-adaptive pretraining might be unavailable. Overall, we consistently find that multi-phase adaptive pretraining offers large gains in task performance.},
  archiveprefix = {arXiv},
  eprint        = {2004.10964},
  file          = {:http\://arxiv.org/pdf/2004.10964v3:PDF},
  keywords      = {cs.CL, cs.LG},
  primaryclass  = {cs.CL},
}

@Article{j-Pham2020,
  author        = {Thang M. Pham and Trung Bui and Long Mai and Anh Nguyen},
  journal       = {arXiv preprint},
  title         = {{Out of Order: How important is the sequential order of words in a sentence in Natural Language Understanding tasks?}},
  year          = {2020},
  month         = dec,
  abstract      = {Do state-of-the-art natural language understanding models care about word order - one of the most important characteristics of a sequence? Not always! We found 75% to 90% of the correct predictions of BERT-based classifiers, trained on many GLUE tasks, remain constant after input words are randomly shuffled. Despite BERT embeddings are famously contextual, the contribution of each individual word to downstream tasks is almost unchanged even after the word's context is shuffled. BERT-based models are able to exploit superficial cues (e.g. the sentiment of keywords in sentiment analysis; or the word-wise similarity between sequence-pair inputs in natural language inference) to make correct decisions when tokens are arranged in random orders. Encouraging classifiers to capture word order information improves the performance on most GLUE tasks, SQuAD 2.0 and out-of-samples. Our work suggests that many GLUE tasks are not challenging machines to understand the meaning of a sentence.},
  archiveprefix = {arXiv},
  eprint        = {2012.15180},
  file          = {:http\://arxiv.org/pdf/2012.15180v1:PDF},
  keywords      = {cs.CL, cs.AI, cs.LG},
  primaryclass  = {cs.CL},
}

@Article{j-Gupta2021,
  author        = {Ashim Gupta and Giorgi Kvernadze and Vivek Srikumar},
  journal       = {arXiv preprint},
  title         = {{BERT \& Family Eat Word Salad: Experiments with Text Understanding}},
  year          = {2021},
  month         = jan,
  abstract      = {In this paper, we study the response of large models from the BERT family to incoherent inputs that should confuse any model that claims to understand natural language. We define simple heuristics to construct such examples. Our experiments show that state-of-the-art models consistently fail to recognize them as ill-formed, and instead produce high confidence predictions on them. As a consequence of this phenomenon, models trained on sentences with randomly permuted word order perform close to state-of-the-art models. To alleviate these issues, we show that if models are explicitly trained to recognize invalid inputs, they can be robust to such attacks without a drop in performance.},
  archiveprefix = {arXiv},
  eprint        = {2101.03453},
  file          = {:http\://arxiv.org/pdf/2101.03453v2:PDF},
  keywords      = {cs.CL, cs.AI},
  primaryclass  = {cs.CL},
}

@Article{j-Izsak2021,
  author        = {Peter Izsak and Moshe Berchansky and Omer Levy},
  journal       = {arXiv preprint},
  title         = {{How to Train BERT with an Academic Budget}},
  year          = {2021},
  month         = apr,
  abstract      = {While large language models \`a la BERT are used ubiquitously in NLP, pretraining them is considered a luxury that only a few well-funded industry labs can afford. How can one train such models with a more modest budget? We present a recipe for pretraining a masked language model in 24 hours, using only 8 low-range 12GB GPUs. We demonstrate that through a combination of software optimizations, design choices, and hyperparameter tuning, it is possible to produce models that are competitive with BERT-base on GLUE tasks at a fraction of the original pretraining cost.},
  archiveprefix = {arXiv},
  eprint        = {2104.07705},
  file          = {:http\://arxiv.org/pdf/2104.07705v1:PDF},
  keywords      = {cs.CL, cs.AI, cs.LG},
  primaryclass  = {cs.CL},
}

@Article{j-Sinha2020,
  author        = {Koustuv Sinha and Prasanna Parthasarathi and Joelle Pineau and Adina Williams},
  journal       = {arXiv preprint},
  title         = {{Unnatural Language Inference}},
  year          = {2020},
  month         = dec,
  abstract      = {Natural Language Understanding has witnessed a watershed moment with the introduction of large pre-trained Transformer networks. These models achieve state-of-the-art on various tasks, notably including Natural Language Inference (NLI). Many studies have shown that the large representation space imbibed by the models encodes some syntactic and semantic information. However, to really "know syntax", a model must recognize when its input violates syntactic rules and calculate inferences accordingly. In this work, we find that state-of-the-art NLI models, such as RoBERTa and BART are invariant to, and sometimes even perform better on, examples with randomly reordered words. With iterative search, we are able to construct randomized versions of NLI test sets, which contain permuted hypothesis-premise pairs with the same words as the original, yet are classified with perfect accuracy by large pre-trained models, as well as pre-Transformer state-of-the-art encoders. We find the issue to be language and model invariant, and hence investigate the root cause. To partially alleviate this effect, we propose a simple training methodology. Our findings call into question the idea that our natural language understanding models, and the tasks used for measuring their progress, genuinely require a human-like understanding of syntax.},
  archiveprefix = {arXiv},
  eprint        = {2101.00010},
  file          = {:http\://arxiv.org/pdf/2101.00010v1:PDF},
  keywords      = {cs.CL, cs.LG},
  primaryclass  = {cs.CL},
}

@Article{j-Sinha2021,
  author        = {Koustuv Sinha and Robin Jia and Dieuwke Hupkes and Joelle Pineau and Adina Williams and Douwe Kiela},
  journal       = {arXiv preprint},
  title         = {{Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little}},
  year          = {2021},
  month         = apr,
  abstract      = {A possible explanation for the impressive performance of masked language model (MLM) pre-training is that such models have learned to represent the syntactic structures prevalent in classical NLP pipelines. In this paper, we propose a different explanation: MLMs succeed on downstream tasks almost entirely due to their ability to model higher-order word co-occurrence statistics. To demonstrate this, we pre-train MLMs on sentences with randomly shuffled word order, and show that these models still achieve high accuracy after fine-tuning on many downstream tasks -- including on tasks specifically designed to be challenging for models that ignore word order. Our models perform surprisingly well according to some parametric syntactic probes, indicating possible deficiencies in how we test representations for syntactic information. Overall, our results show that purely distributional information largely explains the success of pre-training, and underscore the importance of curating challenging evaluation datasets that require deeper linguistic knowledge.},
  archiveprefix = {arXiv},
  eprint        = {2104.06644},
  file          = {:http\://arxiv.org/pdf/2104.06644v1:PDF},
  keywords      = {cs.CL, cs.LG},
  primaryclass  = {cs.CL},
}

@article{j-turner2021bayesian,
  title={Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020},
  author={Turner, Ryan and Eriksson, David and McCourt, Michael and Kiili, Juha and Laaksonen, Eero and Xu, Zhen and Guyon, Isabelle},
  journal={arXiv preprint arXiv:2104.10201},
  year={2021}
}

@article{shahriari2015bayesian,
  title={Taking the human out of the loop: A review of Bayesian optimization},
  author={Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P and De Freitas, Nando},
  journal={Proceedings of the IEEE},
  volume={104},
  number={1},
  pages={148--175},
  year={2015},
  publisher={IEEE}
}

@Article{j-Maddox2021,
  author  = {Wesley J Maddox and Maximilian Balandat and Andrew Gordon Wilson and Eytan Bakshy},
  journal = {arXiv preprint arXiv:2106.12997},
  title   = {{Bayesian Optimization with High-Dimensional Outputs}},
  year    = {2021},
}

@Article{j-Vu2020,
  author  = {Thuy-Trang Vu and Dinh Phung and Gholamreza Haffari},
  journal = {arXiv preprint arXiv:2010.01739},
  title   = {{Effective unsupervised domain adaptation with adversarially trained language models}},
  year    = {2020},
  url     = {https://arxiv.org/abs/2010.01739},
}

@Article{j-Kang2020,
  author  = {Minki Kang and Moonsu Han and Sung Ju Hwang},
  journal = {arXiv preprint arXiv:2010.02705},
  title   = {{Neural mask generator: Learning to generate adaptive word maskings for language model adaptation}},
  year    = {2020},
  url     = {https://arxiv.org/abs/2010.02705},
}

@Article{j-Kalyan2021,
  author        = {Katikapalli Subramanyam Kalyan and Ajit Rajasekharan and Sivanesan Sangeetha},
  journal       = {arXiv preprint},
  title         = {{AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing}},
  year          = {2021},
  month         = aug,
  abstract      = {Transformer-based pretrained language models (T-PTLMs) have achieved great success in almost every NLP task. The evolution of these models started with GPT and BERT. These models are built on the top of transformers, self-supervised learning and transfer learning. Transformed-based PTLMs learn universal language representations from large volumes of text data using self-supervised learning and transfer this knowledge to downstream tasks. These models provide good background knowledge to downstream tasks which avoids training of downstream models from scratch. In this comprehensive survey paper, we initially give a brief overview of self-supervised learning. Next, we explain various core concepts like pretraining, pretraining methods, pretraining tasks, embeddings and downstream adaptation methods. Next, we present a new taxonomy of T-PTLMs and then give brief overview of various benchmarks including both intrinsic and extrinsic. We present a summary of various useful libraries to work with T-PTLMs. Finally, we highlight some of the future research directions which will further improve these models. We strongly believe that this comprehensive survey paper will serve as a good reference to learn the core concepts as well as to stay updated with the recent happenings in T-PTLMs.},
  archiveprefix = {arXiv},
  eprint        = {2108.05542},
  file          = {:http\://arxiv.org/pdf/2108.05542v2:PDF},
  keywords      = {cs.CL},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2108.05542},
}

@article{j-kaplan2020,
  title={Scaling laws for neural language models},
  author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@InProceedings{ip-Nguyen2020,
  author    = {Vu Nguyen and Vaden Masrani and Rob Brekelmans and Michael Osborne and Frank Wood},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {{Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective}},
  year      = {2020},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
  pages     = {5764--5775},
  publisher = {Curran Associates, Inc.},
  volume    = {33},
  url       = {https://proceedings.neurips.cc/paper/2020/file/3f2dff7862a70f97a59a1fa02c3ec110-Paper.pdf},
}

@Article{j-Lee2020,
  author    = {Jinhyuk Lee and Wonjin Yoon and Sungdong Kim and Donghyeon Kim and Sunkyu Kim and Chan Ho So and Jaewoo Kang},
  journal   = {Bioinformatics},
  title     = {{BioBERT: a pre-trained biomedical language representation model for biomedical text mining}},
  year      = {2020},
  number    = {4},
  pages     = {1234--1240},
  volume    = {36},
  publisher = {Oxford University Press},
}

@Article{j-Alsentzer2019,
  author  = {Emily Alsentzer and John R Murphy and Willie Boag and Wei-Hung Weng and Di Jin and Tristan Naumann and Matthew McDermott},
  journal = {arXiv preprint arXiv:1904.03323},
  title   = {{Publicly available clinical BERT embeddings}},
  year    = {2019},
}

@Article{j-Gu2021,
  author    = {Yu Gu and Robert Tinn and Hao Cheng and Michael Lucas and Naoto Usuyama and Xiaodong Liu and Tristan Naumann and Jianfeng Gao and Hoifung Poon},
  journal   = {ACM Transactions on Computing for Healthcare (HEALTH)},
  title     = {{Domain-specific language model pretraining for biomedical natural language processing}},
  year      = {2021},
  number    = {1},
  pages     = {1--23},
  volume    = {3},
  publisher = {ACM New York, NY},
}

@Article{j-Beltagy2019,
  author  = {Iz Beltagy and Kyle Lo and Arman Cohan},
  journal = {arXiv preprint arXiv:1903.10676},
  title   = {{SciBERT: A pretrained language model for scientific text}},
  year    = {2019},
}

@article{kalyan2021ammus,
  title={Ammus: A survey of transformer-based pretrained models in natural language processing},
  author={Kalyan, Katikapalli Subramanyam and Rajasekharan, Ajit and Sangeetha, Sivanesan},
  journal={arXiv preprint arXiv:2108.05542},
  year={2021}
}

@InProceedings{fairseq,
  author    = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  title     = {{fairseq: A Fast, Extensible Toolkit for Sequence Modeling}},
  year      = {2019},
}

@InProceedings{gpytorch,
  author    = {Jacob R Gardner and Geoff Pleiss and David Bindel and Kilian Q Weinberger and Andrew Gordon Wilson},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {{GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration}},
  year      = {2018},
}

@Book{b-Rasmussen2005,
  Title                    = {{Gaussian Processes for Machine Learning}},
  Author                   = {Carl Edward Rasmussen and Christopher K. I. Williams},
  Publisher                = {The MIT Press},
  Year                     = {2005},

  Owner                    = {iurteaga},
  Timestamp                = {2018.05.16}
}

@InProceedings{ip-Titsias2009,
  Title                    = {{Variational Learning of Inducing Variables in Sparse Gaussian Processes}},
  Author                   = {Michalis Titsias},
  Booktitle                = {Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics},
  Year                     = {2009},

  Address                  = {Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA},
  Editor                   = {David van Dyk and Max Welling},
  Month                    = {16--18 Apr},
  Pages                    = {567--574},
  Publisher                = {PMLR},
  Series                   = {Proceedings of Machine Learning Research},
  Volume                   = {5},

  Abstract                 = {Sparse Gaussian process methods that use inducing variables require the selection of the inducing inputs and the kernel hyperparameters. We introduce a variational formulation for sparse approximations that jointly infers the inducing inputs and the kernel hyperparameters by maximizing a lower bound of the true log marginal likelihood. The key property of this formulation is that the inducing inputs are defined to be variational parameters which are selected by minimizing the Kullback-Leibler divergence between the variational distribution and the exact posterior distribution over the latent function values. We apply this technique to regression and we compare it with other approaches in the literature.},
  File                     = {titsias09a.pdf:http\://proceedings.mlr.press/v5/titsias09a/titsias09a.pdf:PDF},
  Owner                    = {iurteaga},
  Timestamp                = {2018.05.16}
}

@InCollection{ic-Snelson2006,
  Title                    = {{Sparse Gaussian Processes using Pseudo-inputs}},
  Author                   = {Edward Snelson and Zoubin Ghahramani},
  Booktitle                = {Advances in Neural Information Processing Systems 18},
  Publisher                = {MIT Press},
  Year                     = {2006},
  Editor                   = {Y. Weiss and B. Sch\"{o}lkopf and J. C. Platt},
  Pages                    = {1257--1264},

  Owner                    = {iurteaga},
  Timestamp                = {2018.05.16}
}

@InProceedings{ip-Wilson2015,
  author    = {Andrew Wilson and Hannes Nickisch},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  title     = {{Kernel Interpolation for Scalable Structured Gaussian Processes (KISS-GP)}},
  year      = {2015},
  address   = {Lille, France},
  editor    = {Bach, Francis and Blei, David},
  month     = {07--09 Jul},
  pages     = {1775--1784},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {37},
  abstract  = {We introduce a new structured kernel interpolation (SKI) framework, which generalises and unifies inducing point methods for scalable Gaussian processes (GPs). SKI methods produce kernel approximations for fast computations through kernel interpolation. The SKI framework clarifies how the quality of an inducing point approach depends on the number of inducing (aka interpolation) points, interpolation strategy, and GP covariance kernel. SKI also provides a mechanism to create new scalable kernel methods, through choosing different kernel interpolation strategies. Using SKI, with local cubic kernel interpolation, we introduce KISS-GP, which is 1) more scalable than inducing point alternatives, 2) naturally enables Kronecker and Toeplitz algebra for substantial additional gains in scalability, without requiring any grid data, and 3) can be used for fast and expressive kernel learning. KISS-GP costs O(n) time and storage for GP inference. We evaluate KISS-GP for kernel matrix approximation, kernel learning, and natural sound modelling.},
  pdf       = {http://proceedings.mlr.press/v37/wilson15.pdf},
  url       = {https://proceedings.mlr.press/v37/wilson15.html},
}

@InProceedings{ip-Flaxman2015,
  author    = {Seth Flaxman and Andrew Wilson and Daniel Neill and Hannes Nickisch and Alex Smola},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  title     = {{Fast Kronecker Inference in Gaussian Processes with non-Gaussian Likelihoods}},
  year      = {2015},
  address   = {Lille, France},
  editor    = {Bach, Francis and Blei, David},
  month     = {07--09 Jul},
  pages     = {607--616},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {37},
  abstract  = {Gaussian processes (GPs) are a flexible class of methods with state of the art performance on spatial statistics applications. However, GPs require O(n^3) computations and O(n^2) storage, and popular GP kernels are typically limited to smoothing and interpolation. To address these difficulties, Kronecker methods have been used to exploit structure in the GP covariance matrix for scalability, while allowing for expressive kernel learning (Wilson et al., 2014). However, fast Kronecker methods have been confined to Gaussian likelihoods. We propose new scalable Kronecker methods for Gaussian processes with non-Gaussian likelihoods, using a Laplace approximation which involves linear conjugate gradients for inference, and a lower bound on the GP marginal likelihood for kernel learning. Our approach has near linear scaling, requiring O(D n^(D+1)/D) operations and O(D n^2/D) storage, for n training data-points on a dense D &gt; 1 dimensional grid. Moreover, we introduce a log Gaussian Cox process, with highly expressive kernels, for modelling spatiotemporal count processes, and apply it to a point pattern (n = 233,088) of a decade of crime events in Chicago. Using our model, we discover spatially varying multiscale seasonal trends and produce highly accurate long-range local area forecasts.},
  pdf       = {http://proceedings.mlr.press/v37/flaxman15.pdf},
  url       = {https://proceedings.mlr.press/v37/flaxman15.html},
}

@InProceedings{ip-Pleiss2018,
  author    = {Geoff Pleiss and Jacob Gardner and Kilian Weinberger and Andrew Gordon Wilson},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  title     = {{Constant-Time Predictive Distributions for Gaussian Processes}},
  year      = {2018},
  editor    = {Dy, Jennifer and Krause, Andreas},
  month     = {10--15 Jul},
  pages     = {4114--4123},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  abstract  = {One of the most compelling features of Gaussian process (GP) regression is its ability to provide well-calibrated posterior distributions. Recent advances in inducing point methods have sped up GP marginal likelihood and posterior mean computations, leaving posterior covariance estimation and sampling as the remaining computational bottlenecks. In this paper we address these shortcomings by using the Lanczos algorithm to rapidly approximate the predictive covariance matrix. Our approach, which we refer to as LOVE (LanczOs Variance Estimates), substantially improves time and space complexity. In our experiments, LOVE computes covariances up to 2,000 times faster and draws samples 18,000 times faster than existing methods, all without sacrificing accuracy.},
  pdf       = {http://proceedings.mlr.press/v80/pleiss18a/pleiss18a.pdf},
  url       = {https://proceedings.mlr.press/v80/pleiss18a.html},
}

@Article{j-Russo2018,
  Title                    = {{A Tutorial on Thompson Sampling}},
  Author                   = {Daniel J. Russo and Benjamin Van Roy and Abbas Kazerouni and Ian Osband and Zheng Wen},
  Journal                  = {{Foundations and Trends\textsuperscript{\textregistered} in Machine Learning}},
  Year                     = {2018},
  Number                   = {1},
  Pages                    = {1-96},
  Volume                   = {11},

  Doi                      = {10.1561/2200000070},
  ISSN                     = {1935-8237},
  Owner                    = {iurteaga},
  Timestamp                = {2018.07.30},
  Url                      = {http://dx.doi.org/10.1561/2200000070}
}

@Article{j-Thompson1933,
  Title                    = {{On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples}},
  Author                   = {William R. Thompson},
  Journal                  = {Biometrika},
  Year                     = {1933},
  Number                   = {3/4},
  Pages                    = {285-294},
  Volume                   = {25},

  ISSN                     = {00063444},
  Owner                    = {iurteaga},
  Publisher                = {[Oxford University Press, Biometrika Trust]},
  Timestamp                = {2016.09.19}
}

@Article{j-Thompson1935,
  Title                    = {{On the Theory of Apportionment}},
  Author                   = {William R. Thompson},
  Journal                  = {American Journal of Mathematics},
  Year                     = {1935},
  Number                   = {2},
  Pages                    = {450-456},
  Volume                   = {57},

  ISSN                     = {00029327, 10806377},
  Owner                    = {iurteaga},
  Publisher                = {Johns Hopkins University Press},
  Timestamp                = {2016.09.20}
}

@Article{spanbert,
  author    = {Mandar Joshi and Danqi Chen and Yinhan Liu and Daniel S Weld and Luke Zettlemoyer and Omer Levy},
  journal   = {Transactions of the Association for Computational Linguistics},
  title     = {{SpanBERT: Improving pre-training by representing and predicting spans}},
  year      = {2020},
  pages     = {64--77},
  volume    = {8},
  publisher = {MIT Press},
}

@InProceedings{ernie,
  author    = {Yu Sun and Shuohuan Wang and Yukun Li and Shikun Feng and Hao Tian and Hua Wu and Haifeng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  title     = {{Ernie 2.0: A continual pre-training framework for language understanding}},
  year      = {2020},
  pages     = {8968--8975},
  volume    = {34},
}

@Article{j-Frazier2018,
  author  = {Peter I. Frazier},
  journal = {arXiv preprint arXiv:1807.02811},
  title   = {{A tutorial on Bayesian optimization}},
  year    = {2018},
}

@InProceedings{ip-Snoek2012,
  author    = {Jasper Snoek and Hugo Larochelle and Ryan P. Adams},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {{Practical Bayesian Optimization of Machine Learning Algorithms}},
  year      = {2012},
  editor    = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  volume    = {25},
  url       = {https://proceedings.neurips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf},
}

@Article{hyperband,
  author  = {Lisha Li and Kevin Jamieson and Giulia DeSalvo and Afshin Rostamizadeh and Ameet Talwalkar},
  journal = {Journal of Machine Learning Research},
  title   = {{Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization}},
  year    = {2018},
  number  = {185},
  pages   = {1--52},
  volume  = {18},
  url     = {http://jmlr.org/papers/v18/16-558.html},
}

@Book{b-evolutionaryalgos,
  author    = {Xinjie Yu and Mitsuo Gen},
  publisher = {Springer Science \& Business Media},
  title     = {{Introduction to evolutionary algorithms}},
  year      = {2010},
}

@Article{j-Calandra2016,
  author    = {Roberto Calandra and Andr{\'e} Seyfarth and Jan Peters and Marc Peter Deisenroth},
  journal   = {Annals of Mathematics and Artificial Intelligence},
  title     = {{Bayesian optimization for learning gaits under uncertainty}},
  year      = {2016},
  number    = {1},
  pages     = {5--23},
  volume    = {76},
  publisher = {Springer},
}

@Article{j-Candelieri2018,
  author    = {Antonio Candelieri and Raffaele Perego and Francesco Archetti},
  journal   = {Journal of Global Optimization},
  title     = {{Bayesian optimization of pump operations in water distribution systems}},
  year      = {2018},
  number    = {1},
  pages     = {213--235},
  volume    = {71},
  publisher = {Springer},
}

@InCollection{ic-Frazier2016,
  author    = {Peter I. Frazier and Jialei Wang},
  booktitle = {Information science for materials discovery and design},
  publisher = {Springer},
  title     = {{Bayesian optimization for materials design}},
  year      = {2016},
  pages     = {45--75},
}

@InProceedings{ip-Hernandez-Lobato2017,
  author       = {Jos{\'e} Miguel Hern{\'a}ndez-Lobato and James Requeima and Edward O Pyzer-Knapp and Al{\'a}n Aspuru-Guzik},
  booktitle    = {International conference on machine learning},
  title        = {{Parallel and distributed Thompson sampling for large-scale accelerated exploration of chemical space}},
  year         = {2017},
  organization = {PMLR},
  pages        = {1470--1479},
}

@Article{j-Negoescu2011,
  author    = {Diana M. Negoescu and Peter I. Frazier and Warren B. Powell},
  journal   = {INFORMS Journal on Computing},
  title     = {{The knowledge-gradient algorithm for sequencing experiments in drug discovery}},
  year      = {2011},
  number    = {3},
  pages     = {346--363},
  volume    = {23},
  publisher = {INFORMS},
}

@Article{j-Gittins1979,
  Title                    = {{Bandit Processes and Dynamic Allocation Indices}},
  Author                   = {J. C. Gittins},
  Journal                  = {Journal of the Royal Statistical Society. Series B (Methodological)},
  Year                     = {1979},
  Number                   = {2},
  Pages                    = {148-177},
  Volume                   = {41},

  Abstract                 = {The paper aims to give a unified account of the central concepts in recent work on bandit processes and dynamic allocation indices; to show how these reduce some previously intractable problems to the problem of calculating such indices; and to describe how these calculations may be carried out. Applications to stochastic scheduling, sequential clinical trials and a class of search problems are discussed.},
  ISSN                     = {00359246},
  Owner                    = {iurteaga},
  Publisher                = {[Royal Statistical Society, Wiley]},
  Timestamp                = {2016.09.20}
}

@Article{j-Auer2002,
  Title                    = {{Finite-time Analysis of the Multiarmed Bandit Problem}},
  Author                   = {Peter Auer and Nicol\`{o} Cesa-Bianchi and Paul Fischer},
  Journal                  = {Machine Learning},
  Year                     = {2002},

  Month                    = may,
  Number                   = {2-3},
  Pages                    = {235--256},
  Volume                   = {47},

  Acmid                    = {599677},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1023/A:1013689704352},
  ISSN                     = {0885-6125},
  Issue_date               = {May-June 2002},
  Keywords                 = {adaptive allocation rules, bandit problems, finite horizon regret},
  Numpages                 = {22},
  Owner                    = {iurteaga},
  Publisher                = {Kluwer Academic Publishers},
  Timestamp                = {2017.05.10}
}

@InProceedings{ip-Kaufmann2012,
  Title                    = {{On Bayesian Upper Confidence Bounds for Bandit Problems}},
  Author                   = {Emilie Kaufmann and Olivier Cappe and Aurelien Garivier},
  Booktitle                = {Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics},
  Year                     = {2012},

  Address                  = {La Palma, Canary Islands},
  Editor                   = {Neil D. Lawrence and Mark Girolami},
  Month                    = {21--23 Apr},
  Pages                    = {592--600},
  Publisher                = {PMLR},
  Series                   = {Proceedings of Machine Learning Research},
  Volume                   = {22},

  Abstract                 = {Stochastic bandit problems have been analyzed from two different perspectives: a frequentist view, where the parameter is a deterministic unknown quantity, and a Bayesian approach, where the parameter is drawn from a prior distribution. We show in this paper that methods derived from this second perspective prove optimal when evaluated using the frequentist cumulated regret as a measure of performance. We give a general formulation for a class of Bayesian index policies that rely on quantiles of the posterior distribution. For binary bandits, we prove that the corresponding algorithm, termed Bayes-UCB, satisfies finite-time regret bounds that imply its asymptotic optimality. More generally, Bayes-UCB appears as an unifying framework for several variants of the UCB algorithm addressing different bandit problems (parametric multi-armed bandits, Gaussian bandits with unknown mean and variance, linear bandits). But the generality of the Bayesian approach makes it possible to address more challenging models. In particular, we show how to handle linear bandits with sparsity constraints by resorting to Gibbs sampling.},
  Owner                    = {iurteaga},
  Timestamp                = {2017.10.11}
}

@Article{j-Slivkins2019,
  author  = {Aleksandrs Slivkins},
  journal = {Foundations and Trends in Machine Learning},
  title   = {{Introduction to Multi-Armed Bandits}},
  year    = {2019},
  issn    = {1935-8237},
  number  = {1-2},
  pages   = {1-286},
  volume  = {12},
  doi     = {10.1561/2200000068},
  url     = {http://dx.doi.org/10.1561/2200000068},
}

@InProceedings{ip-Agrawal2012,
  author    = {Shipra Agrawal and Navin Goyal},
  title     = {{Analysis of Thompson Sampling for the multi-armed bandit problem}},
  booktitle = {{Conference on Learning Theory}},
  year      = {2012},
  pages     = {39--1},
}

@InProceedings{ip-Agrawal2013,
  author    = {Shipra Agrawal and Navin Goyal},
  title     = {{Further Optimal Regret Bounds for Thompson Sampling}},
  booktitle = {{Artificial Intelligence and Statistics}},
  year      = {2013},
  pages     = {99--107},
}

@InProceedings{ip-Lu2017,
  author    = {Xiuyuan Lu and Benjamin Van Roy},
  title     = {{Ensemble sampling}},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  pages     = {3258--3266},
}

@InProceedings{ip-Urteaga2018,
  Title                    = {{Variational inference for the multi-armed contextual bandit}},
  Author                   = {I{\~{n}}igo Urteaga and Chris Wiggins},
  Booktitle                = {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics},
  Year                     = {2018},

  Address                  = {Playa Blanca, Lanzarote, Canary Islands},
  Editor                   = {Amos Storkey and Fernando Perez-Cruz},
  Month                    = {09--11 Apr},
  Pages                    = {698--706},
  Publisher                = {PMLR},
  Series                   = {Proceedings of Machine Learning Research},
  Volume                   = {84},

  Abstract                 = {In many biomedical, science, and engineering problems, one must sequentially decide which action to take next so as to maximize rewards. One general class of algorithms for optimizing interactions with the world, while simultaneously learning how the world operates, is the multi-armed bandit setting and, in particular, the contextual bandit case. In this setting, for each executed action, one observes rewards that are dependent on a given context, available at each interaction with the world. The Thompson sampling algorithm has recently been shown to enjoy provable optimality properties for this set of problems, and to perform well in real-world settings. It facilitates generative and interpretable modeling of the problem at hand. Nevertheless, the design and complexity of the model limit its application, since one must both sample from the distributions modeled and calculate their expected rewards. We here show how these limitations can be overcome using variational inference to approximate complex models, applying to the reinforcement learning case advances developed for the inference case in the machine learning community over the past two decades. We consider contextual multi-armed bandit applications where the true reward distribution is unknown and complex, which we approximate with a mixture model whose parameters are inferred via variational inference. We show how the proposed variational Thompson sampling approach is accurate in approximating the true distribution, and attains reduced regrets even with complex reward distributions. The proposed algorithm is valuable for practical scenarios where restrictive modeling assumptions are undesirable.},
  File                     = {urteaga18a.pdf:http\://proceedings.mlr.press/v84/urteaga18a/urteaga18a.pdf:PDF},
  Owner                    = {iurteaga},
  Timestamp                = {2018.02.06}
}

@InProceedings{ip-Srinivas2010,
  Title                    = {{Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design}},
  Author                   = {Niranjan Srinivas and Andreas Krause and Sham Kakade and Matthias Seeger},
  Booktitle                = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
  Year                     = {2010},

  Address                  = {USA},
  Pages                    = {1015--1022},
  Publisher                = {Omnipress},
  Series                   = {ICML'10},

  Acmid                    = {3104451},
  ISBN                     = {978-1-60558-907-7},
  Location                 = {Haifa, Israel},
  Numpages                 = {8},
  Owner                    = {iurteaga},
  Timestamp                = {2018.05.16}
}

@InProceedings{ip-Gruenewaelder2010,
  Title                    = {{Regret Bounds for Gaussian Process Bandit Problems}},
  Author                   = {Steffen Gr\"unew\"alder and Jean--Yves Audibert and Manfred Opper and John Shawe--Taylor},
  Booktitle                = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  Year                     = {2010},

  Address                  = {Chia Laguna Resort, Sardinia, Italy},
  Editor                   = {Yee Whye Teh and Mike Titterington},
  Month                    = {13--15 May},
  Pages                    = {273--280},
  Publisher                = {PMLR},
  Series                   = {Proceedings of Machine Learning Research},
  Volume                   = {9},

  Abstract                 = {Bandit algorithms are concerned with trading exploration with exploitation where a number of options are available but we can only learn their quality by experimenting with them. We consider the scenario in which the reward distribution for arms is modeled by a Gaussian process and there is no noise in the observed reward. Our main result is to bound the regret experienced by algorithms relative to the a posteriori optimal strategy of playing the best arm throughout based on benign assumptions about the covariance function defining the Gaussian process. We further complement these upper bounds with corresponding lower bounds for particular covariance functions demonstrating that in general there is at most a logarithmic looseness in our upper bounds.},
  Url                      = {http://proceedings.mlr.press/v9/grunewalder10a.html}
}

@InProceedings{ip-Blundell2015,
  author    = {Charles Blundell and Julien Cornebise and Koray Kavukcuoglu and Daan Wierstra},
  booktitle = {Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37},
  title     = {{Weight Uncertainty in Neural Networks}},
  year      = {2015},
  address   = {Lille, France},
  pages     = {1613--1622},
  publisher = {JMLR.org},
  series    = {ICML'15},
  acmid     = {3045290},
  numpages  = {10},
  owner     = {iurteaga},
  timestamp = {2017.11.28},
}

@InCollection{ic-Osband2016,
  Title                    = {{Deep Exploration via Bootstrapped DQN}},
  Author                   = {Ian Osband and Charles Blundell and Alexander Pritzel and Benjamin Van Roy},
  Booktitle                = {Advances in Neural Information Processing Systems 29},
  Publisher                = {Curran Associates, Inc.},
  Year                     = {2016},
  Editor                   = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
  Pages                    = {4026--4034},

  Owner                    = {iurteaga},
  Timestamp                = {2017.11.28}
}

@InProceedings{ip-Riquelme2018,
  Title                    = {{Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling}},
  Author                   = {Carlos Riquelme and George Tucker and Jasper Snoek},
  Booktitle                = {International Conference on Learning Representations},
  Year                     = {2018},

  Owner                    = {iurteaga},
  Timestamp                = {2018.05.15}
}

@Article{glue,
  author  = {Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R Bowman},
  journal = {arXiv preprint arXiv:1804.07461},
  title   = {{GLUE: A multi-task benchmark and analysis platform for natural language understanding}},
  year    = {2018},
}


@inproceedings{puvis-de-chavannes-etal-2021-hyperparameter,
    title = "Hyperparameter Power Impact in Transformer Language Model Training",
    author = "Puvis de Chavannes, Lucas H{\o}yberg  and
      Kongsbak, Mads Guldborg Kjeldgaard  and
      Rantzau, Timmie  and
      Derczynski, Leon",
    booktitle = "Proceedings of the Second Workshop on Simple and Efficient Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Virtual",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.sustainlp-1.12",
    doi = "10.18653/v1/2021.sustainlp-1.12",
    pages = "96--118",
}

@article{patterson2021carbon,
  title={Carbon emissions and large neural network training},
  author={Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
  journal={arXiv preprint arXiv:2104.10350},
  year={2021}
}

# wikitext103
@Article{wikitext103,
  author  = {Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  journal = {arXiv preprint arXiv:1609.07843},
  title   = {Pointer sentinel mixture models},
  year    = {2016},
  url     = {https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/},
}

# RealNews
@InProceedings{c4_realnews,
  author    = {Rowan Zellers and Ari Holtzman and Hannah Rashkin and Yonatan Bisk and Ali Farhadi and Franziska Roesner and Yejin Choi},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {{Defending Against Neural Fake News}},
  year      = {2019},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  publisher = {Curran Associates, Inc.},
  volume    = {32},
  url       = {https://proceedings.neurips.cc/paper/2019/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf},
}

# Mimic
@Article{mimic,
  author  = {Tom J Pollard and Alistair EW Johnson},
  journal = {The MIMIC-III Clinical Database. PhysioNet},
  title   = {{The MIMIC-III clinical database (version 1.4)}},
  year    = {2016},
  url     = {https://doi.org/10.13026/C2XW26},
}

@Misc{robertabase_fairseq,
  author = {Fairseq by Facebook Research},
  month  = sep,
  note   = {Available online at {\url {https://dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz}}},
  title  = {{RoBERTa: A Robustly Optimized BERT Pretraining Approach, pre-trained model using the BERT-base architecture}},
  year   = {2022},
}

@Article{j-Weidinger2021,
  author  = {Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal = {arXiv preprint arXiv:2112.04359},
  title   = {{Ethical and social risks of harm from language models}},
  year    = {2021},
}

@Misc{medMLI,
  author       = {Chaitanya Shivade},
  howpublished = {PhysioNet. \url{https://doi.org/10.13026/C2RS98}},
  title        = {{MedNLI - A Natural Language Inference Dataset For The Clinical Domain (version 1.0.0).}},
  year         = {2019},
}

@Article{Amatriain2023,
  author  = {Xavier Amatriain},
  journal = {arXiv preprint arXiv:2302.07730},
  title   = {{Transformer models: an introduction and catalog}},
  year    = {2023},
}

@Comment{jabref-meta: databaseType:bibtex;}
